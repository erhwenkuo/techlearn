# Preprocess

é™¤äº†åŠ è¼‰æ•¸æ“šé›†ä¹‹å¤–ï¼ŒğŸ¤— æ•¸æ“šé›†çš„å¦ä¸€å€‹ä¸»è¦ç›®æ¨™æ˜¯æä¾›ä¸€çµ„å¤šæ¨£åŒ–çš„é è™•ç†å‡½æ•¸ï¼Œå°‡æ•¸æ“šé›†è½‰æ›ç‚ºé©ç•¶çš„æ ¼å¼ï¼Œä»¥ä¾¿ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æ¡†æ¶é€²è¡Œè¨“ç·´ã€‚

é è™•ç†æ•¸æ“šé›†çš„æ–¹æ³•æœ‰å¾ˆå¤šç¨®ï¼Œé€™å®Œå…¨å–æ±ºæ–¼æ‚¨çš„å…·é«”æ•¸æ“šé›†ã€‚æœ‰æ™‚æ‚¨å¯èƒ½éœ€è¦é‡å‘½ååˆ—ï¼Œæœ‰æ™‚æ‚¨å¯èƒ½éœ€è¦å–æ¶ˆå±•å¹³åµŒå¥—å­—æ®µã€‚ ğŸ¤— æ•¸æ“šé›†æä¾›äº†ä¸€ç¨®å®Œæˆå¤§éƒ¨åˆ†é€™äº›äº‹æƒ…çš„æ–¹æ³•ã€‚ä½†åœ¨å¹¾ä¹æ‰€æœ‰é è™•ç†æƒ…æ³ä¸‹ï¼Œæ ¹æ“šæ‚¨çš„æ•¸æ“šé›†æ¨¡å¼ï¼Œæ‚¨éœ€è¦ï¼š

- å°æ–‡æœ¬æ•¸æ“šé›†é€²è¡Œ tokenizeã€‚
- å°éŸ³é »æ•¸æ“šé›†é‡æ–°æ¡æ¨£ã€‚
- å°‡è®Šæ›æ‡‰ç”¨æ–¼åœ–åƒæ•¸æ“šé›†ã€‚

{==æœ€å¾Œçš„é è™•ç†æ­¥é©Ÿé€šå¸¸æ˜¯å°‡æ•¸æ“šé›†æ ¼å¼è¨­ç½®ç‚ºèˆ‡æ©Ÿå™¨å­¸ç¿’æ¡†æ¶çš„é æœŸè¼¸å…¥æ ¼å¼å…¼å®¹==}ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨é‚„éœ€è¦å®‰è£ ğŸ¤— Transformers å¥—ä»¶ï¼š

```python
pip install transformers
```

##ã€€Tokenize text

æ¨¡å‹ç„¡æ³•è™•ç†åŸå§‹æ–‡æœ¬ï¼Œå› æ­¤æ‚¨éœ€è¦å°‡æ–‡æœ¬è½‰æ›ç‚ºæ•¸å­—ã€‚Tokenization æä¾›äº†ä¸€ç¨®é€šéå°‡æ–‡æœ¬åˆ‡å‰²æˆç‚º token ä¾†å¯¦ç¾æ­¤ç›®çš„çš„æ–¹æ³•ã€‚Token æœ€çµ‚æœƒè½‰æ›ç‚ºæ•¸å­—ã€‚

!!! tip
    æŸ¥çœ‹ Hugging Face èª²ç¨‹ç¬¬ 2 ç« ä¸­çš„ [Tokenizers](https://huggingface.co/course/chapter2/4?fw=pt) éƒ¨åˆ†ï¼Œäº†è§£æœ‰é—œ tokenization å’Œä¸åŒçš„ tokenization æ¼”ç®—æ³•çš„æ›´å¤šä¿¡æ¯ã€‚

1. é¦–å…ˆåŠ è¼‰ [rotten_tomatoes](https://huggingface.co/datasets/rotten_tomatoes) æ•¸æ“šé›†å’Œèˆ‡é è¨“ç·´ [BERT æ¨¡å‹](https://huggingface.co/bert-base-uncased)å°æ‡‰çš„åˆ†è©å™¨ã€‚ä½¿ç”¨èˆ‡é è¨“ç·´æ¨¡å‹ç›¸åŒçš„åˆ†è©å™¨éå¸¸é‡è¦ï¼Œå› ç‚ºæ‚¨å¸Œæœ›ç¢ºä¿æ–‡æœ¬ä»¥ç›¸åŒçš„æ–¹å¼åˆ†å‰²ã€‚

    ```python
    from transformers import AutoTokenizer
    from datasets import load_dataset

    tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
    dataset = load_dataset("rotten_tomatoes", split="train")
    ```

2. å°æ•¸æ“šé›†ä¸­ç¬¬ä¸€è¡Œæ–‡æœ¬èª¿ç”¨ tokenizerï¼š

    ```python
    tokenizer(dataset[0]["text"])
    ```

    çµæœ:

    ```bash
    {'input_ids': [101, 1103, 2067, 1110, 17348, 1106, 1129, 1103, 6880, 1432, 112, 188, 1207, 107, 14255, 1389, 107, 1105, 1115, 1119, 112, 188, 1280, 1106, 1294, 170, 24194, 1256, 3407, 1190, 170, 11791, 5253, 188, 1732, 7200, 10947, 12606, 2895, 117, 179, 7766, 118, 172, 15554, 1181, 3498, 6961, 3263, 1137, 188, 1566, 7912, 14516, 6997, 119, 102], 
    'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
    'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
    ```

    åˆ†è©å™¨è¿”å›ä¸€å€‹åŒ…å«ä¸‰å€‹é …ç›®çš„å­—å…¸ï¼š

    - `input_ids`ï¼šä»£è¡¨æ–‡æœ¬ä¸­ token çš„ idã€‚
    - `token_type_ids`ï¼šå¦‚æœæœ‰å¤šå€‹åºåˆ—ï¼Œå‰‡è¡¨ç¤ºè©² token å±¬æ–¼å“ªå€‹åº
    - `token_type_ids`ï¼šå¦‚æœæœ‰å¤šå€‹åºåˆ—ï¼Œå‰‡è¡¨ç¤ºè©² token å±¬æ–¼å“ªå€‹åºåˆ—ã€‚
    - `attention_mask`ï¼šæŒ‡ç¤ºæ˜¯å¦æ‡‰ masked tokenã€‚

    é€™äº›å€¼å¯¦éš›ä¸Šæ˜¯æ¨¡å‹è¼¸å…¥ã€‚

3. å°æ•´å€‹æ•¸æ“šé›†é€²è¡Œ tokenize çš„æœ€å¿«æ–¹æ³•æ˜¯ä½¿ç”¨ `map()` å‡½æ•¸ã€‚æ­¤å‡½æ•¸é€šéå°‡ tokenizer æ‡‰ç”¨æ–¼æ‰¹é‡æ•¸æ“šè€Œä¸æ˜¯å–®å€‹æ•¸æ“šä¾†åŠ é€Ÿåˆ†è©ã€‚å°‡æ‰¹è™•ç†åƒæ•¸è¨­ç½®ç‚º `True`ï¼š

    ```python
    def tokenization(example):
        return tokenizer(example["text"])

    dataset = dataset.map(tokenization, batched=True)
    ```

4. è¨­ç½®æ•¸æ“šé›†çš„æ ¼å¼ä»¥èˆ‡æ‚¨çš„æ©Ÿå™¨å­¸ç¿’æ¡†æ¶å…¼å®¹ï¼š

    !!! tip "Pytorch"

        ä½¿ç”¨ `set_format()` å‡½æ•¸è¨­ç½®æ•¸æ“šé›†æ ¼å¼ä»¥èˆ‡ PyTorch å…¼å®¹ï¼š

        ```python
        dataset.set_format(type="torch", columns=["input_ids", "token_type_ids", "attention_mask", "labels"])

        dataset.format['type']
        ```

    !!! tip "Tensorflow"

        ä½¿ç”¨ `to_tf_dataset()` å‡½æ•¸è¨­ç½®æ•¸æ“šé›†æ ¼å¼ä»¥èˆ‡ TensorFlow å…¼å®¹ã€‚æ‚¨é‚„éœ€è¦å¾ ğŸ¤— Transformers å°å…¥ data collatorï¼Œä»¥å°‡ä¸åŒçš„åºåˆ—é•·åº¦çµ„åˆæˆä¸€æ‰¹ç›¸åŒé•·åº¦çš„ï¼š

        ```python
        from transformers import DataCollatorWithPadding

        data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="tf")
        tf_dataset = dataset.to_tf_dataset(
            columns=["input_ids", "token_type_ids", "attention_mask"],
            label_cols=["labels"],
            batch_size=2,
            collate_fn=data_collator,
            shuffle=True
        )
        ```

5. æ•¸æ“šé›†ç¾å·²æº–å‚™å¥½ä½¿ç”¨æ‚¨çš„æ©Ÿå™¨å­¸ç¿’æ¡†æ¶é€²è¡Œè¨“ç·´ï¼

## Resample audio signals

åƒæ–‡æœ¬æ•¸æ“šé›†é€™æ¨£çš„éŸ³é »è¼¸å…¥éœ€è¦åˆ†ç‚ºé›¢æ•£çš„æ•¸æ“šé»ã€‚é€™ç¨±ç‚ºæŠ½æ¨£ï¼›æ¡æ¨£ç‡å‘Šè¨´æ‚¨æ¯ç§’æ•ç²å¤šå°‘èªéŸ³ä¿¡è™Ÿã€‚ç¢ºä¿æ•¸æ“šé›†çš„æ¡æ¨£ç‡èˆ‡ç”¨æ–¼é è¨“ç·´æ‚¨æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹çš„æ•¸æ“šçš„æ¡æ¨£ç‡ç›¸åŒ¹é…éå¸¸é‡è¦ã€‚å¦‚æœæ¡æ¨£ç‡ä¸åŒï¼Œé è¨“ç·´æ¨¡å‹å¯èƒ½åœ¨æ•¸æ“šé›†ä¸Šè¡¨ç¾ä¸ä½³ï¼Œå› ç‚ºå®ƒç„¡æ³•è­˜åˆ¥æ¡æ¨£ç‡çš„å·®ç•°ã€‚

1. é¦–å…ˆåŠ è¼‰ [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) æ•¸æ“šé›†ã€éŸ³é »ç‰¹å¾µä»¥åŠèˆ‡é è¨“ç·´çš„ [Wav2Vec2 æ¨¡å‹](https://huggingface.co/facebook/wav2vec2-base-960h)å°æ‡‰çš„ç‰¹å¾µæå–å™¨ï¼š

    ```python
    from transformers import AutoFeatureExtractor
    from datasets import load_dataset, Audio

    feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")
    dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
    ```

2. ç´¢å¼•æ•¸æ“šé›†çš„ç¬¬ä¸€è¡Œã€‚ç•¶æ‚¨èª¿ç”¨æ•¸æ“šé›†çš„éŸ³é »åˆ—æ™‚ï¼Œå®ƒæœƒè‡ªå‹•è§£ç¢¼ä¸¦é‡æ–°æ¡æ¨£ï¼š

    ```python
    dataset[0]["audio"]
    ```

    çµæœ:

    ```bash
    {'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,
            0.        ,  0.        ], dtype=float32),
    'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
    'sampling_rate': 8000}
    ```

3. é–±è®€æ•¸æ“šé›†è¨Šæ¯å¡éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥ç‚ºæ‚¨æä¾›æœ‰é—œæ•¸æ“šé›†çš„é—œéµä¿¡æ¯ã€‚å¿«é€Ÿç€è¦½ä¸€ä¸‹ MInDS-14 æ•¸æ“šé›†è¨Šæ¯å¡ï¼Œæ‚¨æœƒç™¼ç¾æ¡æ¨£ç‡ç‚º 8kHzã€‚åŒæ¨£ï¼Œæ‚¨å¯ä»¥å¾æ¨¡å‹è¨Šæ¯å¡ä¸­ç²å–æœ‰é—œæ¨¡å‹çš„è¨±å¤šè©³ç´°ä¿¡æ¯ã€‚ Wav2Vec2 æ¨¡å‹è¨Šæ¯å¡è¡¨ç¤ºå®ƒæ˜¯åœ¨ 16kHz èªéŸ³éŸ³é »ä¸Šæ¡æ¨£çš„ã€‚é€™æ„å‘³è‘—æ‚¨éœ€è¦å° MInDS-14 æ•¸æ“šé›†é€²è¡Œä¸Šæ¡æ¨£ä»¥åŒ¹é…æ¨¡å‹çš„æ¡æ¨£ç‡ã€‚

    ä½¿ç”¨ `cast_column()` å‡½æ•¸ä¸¦è¨­ç½®éŸ³é »åŠŸèƒ½ä¸­çš„ `sampling_rate` åƒæ•¸ä¾†å°éŸ³é »ä¿¡è™Ÿé€²è¡Œä¸Šæ¡æ¨£ã€‚ç•¶æ‚¨ç¾åœ¨èª¿ç”¨éŸ³é »æ•¸æ“šåˆ—æ™‚ï¼Œå®ƒæœƒè¢«è§£ç¢¼ä¸¦é‡æ–°æ¡æ¨£åˆ° 16kHzï¼š

    ```python
    dataset = dataset.cast_column("audio", Audio(sampling_rate=16_000))

    dataset[0]["audio"]
    ```

    çµæœ:

    ```bash
    {'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
            3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
    'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
    'sampling_rate': 16000}
    ```

4. ä½¿ç”¨  `map()` å‡½æ•¸å°‡æ•´å€‹æ•¸æ“šé›†é‡æ–°æ¡æ¨£è‡³ 16kHzã€‚è©²å‡½æ•¸é€šéå°‡ç‰¹å¾µæå–å™¨æ‡‰ç”¨æ–¼æ‰¹é‡æ¨£æœ¬æ•¸æ“šè€Œä¸æ˜¯å–®å€‹æ¨£æœ¬æ•¸æ“šä¾†åŠ é€Ÿé‡æ¡æ¨£ã€‚å°‡æ‰¹è™•ç†åƒæ•¸è¨­ç½®ç‚º `True`ï¼š

    ```python
    def preprocess_function(examples):
        audio_arrays = [x["array"] for x in examples["audio"]]
        inputs = feature_extractor(
            audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True
        )
        return inputs

    dataset = dataset.map(preprocess_function, batched=True)
    ```

5. æ•¸æ“šé›†ç¾å·²æº–å‚™å¥½ä½¿ç”¨æ‚¨çš„æ©Ÿå™¨å­¸ç¿’æ¡†æ¶é€²è¡Œè¨“ç·´ï¼

## Apply data augmentations

å°åœ–åƒæ•¸æ“šé›†é€²è¡Œçš„æœ€å¸¸è¦‹çš„é è™•ç†æ˜¯ **æ•¸æ“šå¢å¼·**ï¼Œé€™æ˜¯ä¸€å€‹åœ¨ä¸æ”¹è®Šæ•¸æ“šå«ç¾©çš„æƒ…æ³ä¸‹å‘åœ–åƒå¼•å…¥éš¨æ©Ÿè®ŠåŒ–çš„éç¨‹ã€‚é€™å¯èƒ½æ„å‘³è‘—æ›´æ”¹åœ–åƒçš„é¡è‰²å±¬æ€§æˆ–éš¨æ©Ÿè£å‰ªåœ–åƒã€‚æ‚¨å¯ä»¥è‡ªç”±ä½¿ç”¨æ‚¨å–œæ­¡çš„ä»»ä½•æ•¸æ“šå¢å¼·åº«ï¼ŒğŸ¤— æ•¸æ“šé›†å°‡å¹«åŠ©æ‚¨å°‡æ•¸æ“šå¢å¼·æ‡‰ç”¨åˆ°æ•¸æ“šé›†ã€‚

1. é¦–å…ˆåŠ è¼‰ [Beans](https://huggingface.co/datasets/beans) æ•¸æ“šé›†ã€Image ç‰¹å¾µä»¥åŠèˆ‡é è¨“ç·´ [ViT æ¨¡å‹](https://huggingface.co/google/vit-base-patch16-224-in21k)å°æ‡‰çš„ç‰¹å¾µæå–å™¨ï¼š

    ```python
    from transformers import AutoFeatureExtractor
    from datasets import load_dataset, Image

    feature_extractor = AutoFeatureExtractor.from_pretrained("google/vit-base-patch16-224-in21k")

    dataset = load_dataset("beans", split="train")
    ```

2. ç´¢å¼•æ•¸æ“šé›†çš„ç¬¬ä¸€è¡Œã€‚ç•¶æ‚¨èª¿ç”¨æ•¸æ“šé›†çš„åœ–åƒåˆ—æ™‚ï¼Œåº•å±¤ PIL å°è±¡æœƒè‡ªå‹•è§£ç¢¼ç‚ºåœ–åƒã€‚

```python
dataset[0]["image"]
```

3. ç¾åœ¨ï¼Œæ‚¨å¯ä»¥å°åœ–åƒæ‡‰ç”¨ä¸€äº›è®Šæ›ã€‚è«‹éš¨æ„æŸ¥çœ‹ torchvision ä¸­æä¾›çš„[å„ç¨®è®Šæ›](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py)ï¼Œç„¶å¾Œé¸æ“‡æ‚¨æƒ³è¦å˜—è©¦çš„è®Šæ›ã€‚æ­¤ç¤ºä¾‹æ‡‰ç”¨éš¨æ©Ÿæ—‹è½‰åœ–åƒçš„è®Šæ›ï¼š

    ```python
    from torchvision.transforms import RandomRotation

    rotate = RandomRotation(degrees=(0, 90))

    def transforms(examples):
        examples["pixel_values"] = [rotate(image.convert("RGB")) for image in examples["image"]]
        return examples
    ```

4. ä½¿ç”¨ `set_transform()` å‡½æ•¸å³æ™‚æ‡‰ç”¨è®Šæ›ã€‚ç•¶æ‚¨ç´¢å¼•åœ–åƒåƒç´ å€¼æ™‚ï¼Œæœƒæ‡‰ç”¨è®Šæ›ï¼Œä¸¦ä¸”åœ–åƒæœƒæ—‹è½‰ã€‚

    ```python
    dataset.set_transform(transforms)
    dataset[0]["pixel_values"]
    ```

5. æ•¸æ“šé›†ç¾å·²æº–å‚™å¥½ä½¿ç”¨æ‚¨çš„æ©Ÿå™¨å­¸ç¿’æ¡†æ¶é€²è¡Œè¨“ç·´ï¼
