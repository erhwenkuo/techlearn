# Process

ğŸ¤— Datasets æä¾›äº†è¨±å¤šç”¨æ–¼ä¿®æ”¹æ•¸æ“šé›†çš„çµæ§‹å’Œå…§å®¹çš„å·¥å…·ã€‚é€™äº›å·¥å…·å°æ–¼æ•´ç†æ•¸æ“šé›†ã€å‰µå»ºé™„åŠ åˆ—ã€åœ¨åŠŸèƒ½å’Œæ ¼å¼ä¹‹é–“é€²è¡Œè½‰æ›ç­‰éå¸¸é‡è¦ã€‚

æœ¬æŒ‡å—å°‡å‘æ‚¨å±•ç¤ºå¦‚ä½•ï¼š

- å°è¡Œ(rows)é‡æ–°æ’åºä¸¦æ‹†åˆ†æ•¸æ“šé›†ã€‚
- é‡å‘½åå’Œåˆªé™¤åˆ—(columns)ä»¥åŠå…¶ä»–å¸¸è¦‹çš„åˆ—æ“ä½œã€‚
- å°‡ processing function æ‡‰ç”¨æ–¼æ•¸æ“šé›†ä¸­çš„æ¯å€‹ç¤ºä¾‹è¡Œ(row)ã€‚
- ä¸²æ¥æ•¸æ“šé›†ã€‚
- æ‡‰ç”¨è‡ªå®šç¾©æ ¼å¼è½‰æ›ã€‚
- ä¿å­˜ä¸¦å°å‡ºè™•ç†å¾Œçš„æ•¸æ“šé›†ã€‚

æœ‰é—œè™•ç†å…¶ä»–æ•¸æ“šé›†æ¨¡æ…‹çš„æ›´å¤šè©³ç´°ä¿¡æ¯ï¼Œè«‹æŸ¥çœ‹ [process audio dataset](https://huggingface.co/docs/datasets/audio_process) æŒ‡å—ã€[process image dataset](https://huggingface.co/docs/datasets/image_process) æŒ‡å—æˆ– [process text dataset](https://huggingface.co/docs/datasets/nlp_process) æŒ‡å—ã€‚

æœ¬æŒ‡å—ä¸­çš„ç¤ºä¾‹ä½¿ç”¨ [MRPC]() æ•¸æ“šé›†ï¼Œä½†è«‹éš¨æ„åŠ è¼‰æ‚¨é¸æ“‡çš„ä»»ä½•æ•¸æ“šé›†ä¸¦ç¹¼çºŒæ“ä½œï¼

```python
from datasets import load_dataset

dataset = load_dataset("glue", "mrpc", split="train")
```

!!! tip
    æœ¬æŒ‡å—ä¸­çš„æ‰€æœ‰è™•ç†æ–¹æ³•éƒ½æœƒè¿”å›ä¸€å€‹æ–°çš„ [Dataset](https://huggingface.co/docs/datasets/v2.14.0/en/package_reference/main_classes#datasets.Dataset) ç‰©ä»¶ã€‚

## Sort, shuffle, select, split, and shard

æœ‰å¹¾å€‹å‡½æ•¸å¯ç”¨æ–¼é‡æ–°æ’åˆ—æ•¸æ“šé›†çš„çµæ§‹ã€‚é€™äº›å‡½æ•¸å°æ–¼åƒ…é¸æ“‡æ‰€éœ€çš„è¡Œã€å‰µå»ºè¨“ç·´å’Œæ¸¬è©¦åˆ†å‰²ä»¥åŠå°‡éå¸¸å¤§çš„æ•¸æ“šé›†åˆ†å‰²æˆè¼ƒå°çš„åˆ†å¡Šéå¸¸æœ‰ç”¨ã€‚

###ã€€Sort

ä½¿ç”¨ `sort()` æ ¹æ“šåˆ—å€¼(column)çš„æ•¸å€¼é€²è¡Œæ’åºã€‚æä¾›çš„åˆ—çš„æ¬„ä½å(column name)å¿…é ˆèˆ‡ NumPy å…¼å®¹ã€‚

```python
dataset["label"][:10]
sorted_dataset = dataset.sort("label")
sorted_dataset["label"][:10]
sorted_dataset["label"][-10:]
```

çµæœ:

```bash
[1, 0, 1, 0, 1, 1, 0, 1, 0, 0]
```

```python
sorted_dataset = dataset.sort("label")

sorted_dataset["label"][:10]
```

çµæœ:

```bash
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
```

```python
sorted_dataset["label"][-10:]
```

çµæœ:

```bash
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```

åœ¨åº•å±¤ï¼Œé€™æœƒå‰µå»ºä¸€å€‹æ ¹æ“šåˆ—å€¼æ’åºçš„ç´¢å¼•åˆ—è¡¨ã€‚ç„¶å¾Œï¼Œè©²ç´¢å¼•æ˜ å°„ç”¨æ–¼è¨ªå•åŸºç¤ Arrow è¡¨ä¸­çš„æ­£ç¢ºè¡Œã€‚

### Shuffle

`shuffle()` å‡½æ•¸éš¨æ©Ÿé‡æ–°æ’åˆ—åˆ—å€¼(column values)ã€‚å¦‚æœæ‚¨æƒ³æ›´å¥½åœ°æ§åˆ¶ç”¨æ–¼æ´—ç‰Œæ•¸æ“šé›†çš„ç®—æ³•ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤å‡½æ•¸ä¸­æŒ‡å®š `generator` åƒæ•¸ä¾†ä½¿ç”¨ä¸åŒçš„ `numpy.random.Generator`ã€‚

```python
shuffled_dataset = sorted_dataset.shuffle(seed=42)

shuffled_dataset["label"][:10]
```

çµæœ:

```bash
[1, 1, 1, 0, 1, 1, 1, 1, 1, 0]
```

Shuffling ç²å–ç´¢å¼•åˆ—è¡¨ [0:len(my_dataset)] ä¸¦å‰µå»ºä¸€å€‹æ–°çš„ shuffling çš„ç´¢å¼•æ˜ å°„ã€‚ç„¶è€Œï¼Œä¸€æ—¦æ‚¨çš„æ•¸æ“šé›†å…·æœ‰ç´¢å¼•æ˜ å°„ï¼Œé€Ÿåº¦å°±æœƒè®Šæ…¢ 10 å€ã€‚

é€™æ˜¯å› ç‚ºéœ€è¦ä¸€å€‹é¡å¤–çš„æ­¥é©Ÿä¾†ä½¿ç”¨ç´¢å¼•æ˜ å°„ä¾†è®€å–è¦è®€å–çš„è¡Œç´¢å¼•ï¼Œæœ€é‡è¦çš„æ˜¯ï¼Œæ‚¨ä¸å†è®€å–é€£çºŒçš„æ•¸æ“šå¡Šã€‚

è¦æ¢å¾©é€Ÿåº¦ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ [`Dataset.flatten_indices()`](https://huggingface.co/docs/datasets/v2.14.0/en/package_reference/main_classes#datasets.Dataset.flatten_indices) å†æ¬¡é‡å¯«ç£ç›¤ä¸Šçš„æ•´å€‹æ•¸æ“šé›†ï¼Œé€™æœƒåˆªé™¤ç´¢å¼•æ˜ å°„ã€‚æˆ–è€…ï¼Œæ‚¨å¯ä»¥åˆ‡æ›åˆ° [IterableDataset](https://huggingface.co/docs/datasets/v2.14.0/en/package_reference/main_classes#datasets.IterableDataset) ä¸¦åˆ©ç”¨å…¶å¿«é€Ÿè¿‘ä¼¼çš„æ–¹æ³• [IterableDataset.shuffle()](https://huggingface.co/docs/datasets/v2.14.0/en/package_reference/main_classes#datasets.IterableDataset.shuffle)ï¼š

```python
iterable_dataset = dataset.to_iterable_dataset(num_shards=128)

shuffled_iterable_dataset = iterable_dataset.shuffle(seed=42, buffer_size=1000)
```

### Select and Filter

æœ‰å…©å€‹é¸é …å¯ç”¨æ–¼éæ¿¾æ•¸æ“šé›†ä¸­çš„è¡Œï¼š`select()` å’Œ `filter()`ã€‚

- `select()` æ ¹æ“šç´¢å¼•åˆ—è¡¨è¿”å›è¡Œ(rows)ï¼š

    ```python
    small_dataset = dataset.select([0, 10, 20, 30, 40, 50])

    len(small_dataset)
    ```

    çµæœ:

    ```bash
    6
    ```

- `filter()` è¿”å›ç¬¦åˆæŒ‡å®šæ¢ä»¶çš„è¡Œ(rows)ï¼š

    ```python
    start_with_ar = dataset.filter(lambda example: example["sentence1"].startswith("Ar"))

    print(len(start_with_ar))

    print(start_with_ar["sentence1"])
    ```

    çµæœ:

    ```bash
    6

    ['Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .',
    'Arison said Mann may have been one of the pioneers of the world music movement and he had a deep love of Brazilian music .',
    'Arts helped coach the youth on an eighth-grade football team at Lombardi Middle School in Green Bay .',
    'Around 9 : 00 a.m. EDT ( 1300 GMT ) , the euro was at $ 1.1566 against the dollar , up 0.07 percent on the day .',
    "Arguing that the case was an isolated example , Canada has threatened a trade backlash if Tokyo 's ban is not justified on scientific grounds .",
    'Artists are worried the plan would harm those who need help most - performers who have a difficult time lining up shows .'
    ]    
    ```

    å¦‚æœè¨­å®š `with_indices=True`ï¼Œ`filter()` é‚„å¯ä»¥æŒ‰ç´¢å¼•ä¾†é€²è¡Œéæ¿¾ï¼š

    ```python
    even_dataset = dataset.filter(lambda example, idx: idx % 2 == 0, with_indices=True)

    print(len(even_dataset))

    print(len(dataset) / 2)
    ```

    ```bash
    1834
    
    1834.0
    ```

    é™¤éè¦ä¿ç•™â€‹â€‹çš„ç´¢å¼•åˆ—è¡¨æ˜¯é€£çºŒçš„ï¼Œå¦å‰‡é€™äº›æ–¹æ³•é‚„æœƒåœ¨å¹•å¾Œå‰µå»ºç´¢å¼•æ˜ å°„ã€‚


### Split

å¦‚æœæ‚¨çš„æ•¸æ“šé›†é‚„æ²’æœ‰å€éš” `train` å’Œ `test` çš„ splitsï¼Œ[`train_test_split()`](https://huggingface.co/docs/datasets/v2.14.0/en/package_reference/main_classes#datasets.Dataset.train_test_split) å‡½æ•¸æœƒå‰µå»ºå®ƒå€‘ã€‚é€™å…è¨±æ‚¨èª¿æ•´æ¯å€‹åˆ†å‰²ä¸­æ¨£æœ¬çš„ç›¸å°æ¯”ä¾‹æˆ–çµ•å°æ•¸é‡ã€‚åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œä½¿ç”¨ `test_size` åƒæ•¸å‰µå»ºä¸€å€‹ä½”åŸå§‹æ•¸æ“šé›† 10% çš„æ¸¬è©¦åˆ†å‰²ï¼š

```python
new_dataset = dataset.train_test_split(test_size=0.1)

print(new_dataset)
```

çµæœ:

```bash
{'train': Dataset(schema: {'sentence1': 'string', 'sentence2': 'string', 'label': 'int64', 'idx': 'int32'}, num_rows: 3301),
'test': Dataset(schema: {'sentence1': 'string', 'sentence2': 'string', 'label': 'int64', 'idx': 'int32'}, num_rows: 367)}
```

æ¯”å°ä¸€ä¸‹åŸæœ‰çš„ dataset:

```python
print(0.1 * len(dataset))
```

çµæœ:

```bash
366.8
```

é»˜èªæƒ…æ³ä¸‹ï¼Œåˆ†å‰²æ˜¯éš¨æ©Ÿæ’åˆ—çš„ï¼Œä½†æ‚¨å¯ä»¥è¨­ç½® `shuffle=False` ä¾†é˜²æ­¢éš¨æ©Ÿæ’åˆ—ã€‚

### Shard

ğŸ¤— æ•¸æ“šé›†æ”¯æŒåˆ†ç‰‡(sharding)ï¼Œå°‡éå¸¸å¤§çš„æ•¸æ“šé›†åŠƒåˆ†ç‚ºé å®šç¾©æ•¸é‡çš„å¡Šã€‚åœ¨ `shard()` ä¸­æŒ‡å®š `num_shards` åƒæ•¸ä¾†ç¢ºå®šå°‡æ•¸æ“šé›†æ‹†åˆ†ç‚ºçš„åˆ†ç‰‡æ•¸é‡ã€‚æ‚¨é‚„éœ€è¦æä¾›è¦ä½¿ç”¨ç´¢å¼•åƒæ•¸è¿”å›çš„åˆ†ç‰‡ã€‚

ä¾‹å¦‚ï¼Œ[imdb](https://huggingface.co/datasets/imdb) æ•¸æ“šé›†æœ‰ `25000` å€‹ç¤ºä¾‹ï¼š

```python
from datasets import load_dataset

datasets = load_dataset("imdb", split="train")

print(dataset)
```

çµæœ:

```bash
Dataset({
    features: ['text', 'label'],
    num_rows: 25000
})
```

å°‡æ•¸æ“šé›†åˆ†ç‰‡ç‚ºå››å€‹å¡Š(chunks)å¾Œï¼Œç¬¬ä¸€å€‹åˆ†ç‰‡(shard)å°‡åªæœ‰ `6250` å€‹ç¤ºä¾‹ï¼š

```python
first_shard_dataset = dataset.shard(num_shards=4, index=0)

print(first_shard_dataset)

print(25000/4)
```

çµæœ:

```bash
Dataset({
    features: ['text', 'label'],
    num_rows: 6250
})

6250.0
```

## Rename, remove, cast, and flatten

ä»¥ä¸‹å‡½æ•¸å…è¨±æ‚¨ä¿®æ”¹æ•¸æ“šé›†çš„åˆ—(column)ã€‚é€™äº›å‡½æ•¸å°æ–¼é‡å‘½åæˆ–åˆªé™¤åˆ—ã€å°‡åˆ—æ›´æ”¹ç‚ºä¸€çµ„æ–°åŠŸèƒ½ä»¥åŠå±•å¹³åµŒå¥—åˆ—çµæ§‹éå¸¸æœ‰ç”¨ã€‚

### Rename

ç•¶æ‚¨éœ€è¦é‡å‘½åæ•¸æ“šé›†ä¸­çš„åˆ—(column)æ™‚ï¼Œè«‹ä½¿ç”¨ `rename_column()`ã€‚èˆ‡åŸå§‹åˆ—é—œè¯çš„ç‰¹å¾µå¯¦éš›ä¸Šè¢«ç§»å‹•åˆ°æ–°åˆ—åç¨±ä¸‹ï¼Œè€Œä¸æ˜¯åƒ…åƒ…å°±åœ°æ›¿æ›åŸå§‹åˆ—ã€‚

ç‚º `rename_column()` æä¾›åŸå§‹åˆ—çš„åç¨±å’Œæ–°åˆ—çš„åç¨±ï¼š

```python
print(dataset)

dataset = dataset.rename_column("sentence1", "sentenceA")
dataset = dataset.rename_column("sentence2", "sentenceB")

print(dataset)
```

çµæœ:

```bash
# before
Dataset({
    features: ['sentence1', 'sentence2', 'label', 'idx'],
    num_rows: 3668
})

# after
Dataset({
    features: ['sentenceA', 'sentenceB', 'label', 'idx'],
    num_rows: 3668
})
```

### Remove

ç•¶æ‚¨éœ€è¦åˆªé™¤ä¸€åˆ—æˆ–å¤šåˆ—æ™‚ï¼Œè«‹å‘ `remove_columns()` å‡½æ•¸æä¾›è¦åˆªé™¤çš„åˆ—åç¨±ã€‚é€šéæä¾›åˆ—åç¨±åˆ—è¡¨ä¾†åˆªé™¤å¤šå€‹åˆ—ï¼š

```python
dataset = dataset.remove_columns("label")

print(dataset)
```

çµæœ:

```bash
Dataset({
    features: ['sentence1', 'sentence2', 'idx'],
    num_rows: 3668
})
```

```python
dataset = dataset.remove_columns(["sentence1", "sentence2"])

print(dataset)
```

çµæœ:

```bash
Dataset({
    features: ['idx'],
    num_rows: 3668
})
```

### Cast

`cast()` å‡½æ•¸è½‰æ›ä¸€åˆ—æˆ–å¤šåˆ—çš„ç‰¹å¾µé¡å‹ã€‚è©²å‡½æ•¸æ¥å—æ‚¨çš„æ–°åŠŸèƒ½ä½œç‚ºå…¶åƒæ•¸ã€‚ä¸‹é¢çš„ç¤ºä¾‹æ¼”ç¤ºç­å¦‚ä½•æ›´æ”¹ `ClassLabel` å’Œ `Value` é€™å…©å€‹åœ¨ dataset è£¡çš„ feature æ•¸æ“šï¼š

```python
print(dataset.features)
```

çµæœ:

```bash
{'sentence1': Value(dtype='string', id=None),
'sentence2': Value(dtype='string', id=None),
'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], names_file=None, id=None),
'idx': Value(dtype='int32', id=None)}
```

```python
from datasets import ClassLabel, Value

new_features = dataset.features.copy()

new_features["label"] = ClassLabel(names=["negative", "positive"])

new_features["idx"] = Value("int64")

dataset = dataset.cast(new_features)

print(dataset.features)
```

çµæœ:

```bash
{'sentence1': Value(dtype='string', id=None),
'sentence2': Value(dtype='string', id=None),
'label': ClassLabel(num_classes=2, names=['negative', 'positive'], names_file=None, id=None),
'idx': Value(dtype='int64', id=None)}
```

!!! tip
    åƒ…ç•¶åŸå§‹ feature type å’Œæ–° feature type å…¼å®¹æ™‚ï¼Œ`cast()` æ‰æœ‰æ•ˆã€‚ä¾‹å¦‚ï¼Œå¦‚æœåŸå§‹åˆ—åƒ…åŒ…å« 1 å’Œ 0ï¼Œå‰‡å¯ä»¥å°‡è¦ç´ é¡å‹ `Value("int32")` çš„åˆ—è½‰æ›ç‚º `Value("bool")`ã€‚

ä½¿ç”¨ [`cast_column()`](https://huggingface.co/docs/datasets/v2.14.0/en/package_reference/main_classes#datasets.Dataset.cast_column) å‡½æ•¸æ›´æ”¹å–®å€‹åˆ—çš„è¦ç´ é¡å‹ã€‚å°‡ `column name` åŠ `new feature type` ä½œç‚ºåƒæ•¸å‚³éï¼š

```python
print(dataset.features)
```

çµæœ:

```bash
{'audio': Audio(sampling_rate=44100, mono=True, id=None)}
```

```python
dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))

print(dataset.features)
```

çµæœ:

```bash
{'audio': Audio(sampling_rate=16000, mono=True, id=None)}
```

### Flatten

æœ‰æ™‚ï¼Œåˆ—å¯ä»¥æ˜¯å¤šç¨®é¡å‹çš„åµŒå¥—çµæ§‹ã€‚çœ‹ä¸€ä¸‹ [SQuAD](https://huggingface.co/datasets/squad) æ•¸æ“šé›†ä¸­çš„åµŒå¥—çµæ§‹ï¼š

```python
from datasets import load_dataset

dataset = load_dataset("squad", split="train")

print(dataset.features)
```

çµæœ:

```bash hl_lines="1"
{'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),
'context': Value(dtype='string', id=None),
'id': Value(dtype='string', id=None),
'question': Value(dtype='string', id=None),
'title': Value(dtype='string', id=None)}
```

`answers` æ¬„ä½åŒ…å«å…©å€‹å­æ¬„ä½ï¼š `text` å’Œ `answer_start`ã€‚ä½¿ç”¨ `flatten()` å‡½æ•¸å°‡å­æ¬„ä½æå–åˆ°å®ƒå€‘è‡ªå·±çš„å–®ç¨åˆ—ä¸­ï¼š

```python
flat_dataset = dataset.flatten()

print(flat_dataset)
```

çµæœ:

```bash hl_lines="1"
Dataset({
    features: ['id', 'title', 'context', 'question', 'answers.text', 'answers.answer_start'],
 num_rows: 87599
})
```

è«‹æ³¨æ„ï¼Œå­æ¬„ä½ç¾åœ¨æ˜¯å®ƒå€‘è‡ªå·±çš„ç¨ç«‹æ¬„ä½äº†ï¼š`answers.text` å’Œ `answer.answer_start`ã€‚

