---
draft: false 
date: 2023-10-27
categories:
  - GenAI
  - Copilot
---

# Personal Copilot: è¨“ç·´è‡ªå·±çš„ç¨‹å¼è¨­è¨ˆåŠ©æ‰‹

åœ¨ä¸æ–·ç™¼å±•çš„ç¨‹å¼è¨­è¨ˆå’Œè»Ÿé«”é–‹ç™¼é ˜åŸŸï¼Œå°æ•ˆç‡å’Œç”Ÿç”¢åŠ›çš„è¿½æ±‚å¸¶ä¾†äº†é¡¯è‘—çš„å‰µæ–°ã€‚å…¶ä¸­ä¸€é …å‰µæ–°å°±æ˜¯ [Codex](https://openai.com/blog/openai-codex)ã€[StarCoder](https://arxiv.org/abs/2305.06161) å’Œ [Code Llama](https://arxiv.org/abs/2308.12950) ç­‰ç¨‹å¼ç¢¼ç”¢ç”Ÿæ¨¡å‹çš„å‡ºç¾ã€‚é€™äº›æ¨¡å‹åœ¨ç”¢ç”Ÿé¡ä¼¼äººé¡çš„ç¨‹å¼ç¢¼ç‰‡æ®µæ–¹é¢è¡¨ç¾å‡ºäº†å“è¶Šçš„èƒ½åŠ›ï¼Œå¾è€Œé¡¯ç¤ºå‡ºä½œç‚ºç·¨ç¢¼åŠ©æ‰‹çš„å·¨å¤§æ½›åŠ›ã€‚

ç„¶è€Œï¼Œé›–ç„¶é€™äº›é å…ˆè¨“ç·´çš„æ¨¡å‹å¯ä»¥åœ¨ä¸€ç³»åˆ—ä»»å‹™ä¸­è¡¨ç¾å‡ºè‰²ï¼Œä½†é‚„æœ‰ä¸€å€‹ä»¤äººèˆˆå¥®çš„å¯èƒ½æ€§ï¼šèƒ½å¤ æ ¹æ“šæ‚¨çš„ç‰¹å®šéœ€æ±‚å®šè£½ç¨‹å¼ç¢¼ç”¢ç”Ÿæ¨¡å‹ã€‚æƒ³æƒ³å¯ä»¥åœ¨ä¼æ¥­è¦æ¨¡ä¸Šåˆ©ç”¨çš„å€‹äººåŒ–ç·¨ç¢¼åŠ©æ‰‹ã€‚

åœ¨é€™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å€‘å±•ç¤ºç­å¦‚ä½•å»ºç«‹ HugCoder ğŸ¤—ï¼Œé€™æ˜¯ä¸€å€‹æ ¹æ“š [Huggingface GitHub](https://github.com/huggingface) çµ„ç¹”çš„å…¬å…±å„²å­˜åº«ä¸­çš„ç¨‹å¼ç¢¼å…§å®¹é€²è¡Œå¾®èª¿çš„ç¨‹å¼ç¢¼ LLMã€‚æˆ‘å€‘å°‡è¨è«–æˆ‘å€‘çš„è³‡æ–™æ”¶é›†å·¥ä½œæµç¨‹ã€è¨“ç·´å¯¦é©—å’Œä¸€äº›æœ‰è¶£çš„çµæœã€‚é€™å°‡ä½¿æ‚¨èƒ½å¤ æ ¹æ“šæ‚¨çš„å°ˆæœ‰ç¨‹å¼ç¢¼åº«å‰µå»ºæ‚¨è‡ªå·±çš„å€‹äººå‰¯é§•é§›ã€‚æˆ‘å€‘å°‡ç‚ºæ‚¨ç•™ä¸‹è©²é …ç›®çš„ä¸€äº›é€²ä¸€æ­¥æ“´å±•ä»¥ä¾›å¯¦é©—ã€‚

è®“æˆ‘å€‘é–‹å§‹å§ğŸš€

![](./personal-copilot/personal-copilot-demo.gif)

## è³‡æ–™æ”¶é›†å·¥ä½œæµç¨‹

æˆ‘å€‘æƒ³è¦çš„è³‡æ–™é›†åœ¨æ¦‚å¿µä¸Šå¾ˆç°¡å–®ï¼Œæˆ‘å€‘çš„çµæ§‹å¦‚ä¸‹ï¼š


|Repository Name	|Filepath in the Repository	|File Contents|
|---	|---	|---|
|---	|---	|---|

ä½¿ç”¨ [Python GitHub API](https://github.com/PyGithub/PyGithub) å¾ GitHub æŠ“å–ç¨‹å¼ç¢¼å…§å®¹éå¸¸ç°¡å–®ã€‚ç„¶è€Œï¼Œæ ¹æ“šå„²å­˜åº«çš„æ•¸é‡ä»¥åŠå„²å­˜åº«ä¸­ç¨‹å¼ç¢¼æª”æ¡ˆçš„æ•¸é‡ï¼Œäººå€‘å¯èƒ½å¾ˆå®¹æ˜“é‡åˆ° API é€Ÿç‡é™åˆ¶å•é¡Œã€‚

ç‚ºäº†é˜²æ­¢æ­¤é¡å•é¡Œï¼Œæˆ‘å€‘æ±ºå®šåœ¨æœ¬åœ°å…‹éš†æ‰€æœ‰å…¬å…±å„²å­˜åº«ä¸¦å¾ä¸­æå–å…§å®¹ï¼Œè€Œä¸æ˜¯é€é APIã€‚æˆ‘å€‘ä½¿ç”¨ Python ä¸­çš„å¤šè™•ç†æ¨¡çµ„ä¸¦è¡Œä¸‹è¼‰æ‰€æœ‰å„²å­˜åº«ï¼Œå¦‚è©²[ä¸‹è¼‰è…³æœ¬](https://github.com/sayakpaul/hf-codegen/blob/main/data/parallel_clone_repos.py)æ‰€ç¤ºã€‚

å„²å­˜åº«é€šå¸¸å¯ä»¥åŒ…å«éç¨‹å¼ç¢¼æ–‡ä»¶ï¼Œä¾‹å¦‚åœ–åƒã€ç°¡å ±å’Œå…¶ä»–æ•¸æ“šè³‡ç”¢ã€‚æˆ‘å€‘å°æ”¶é›†å®ƒå€‘ä¸æ„Ÿèˆˆè¶£ã€‚æˆ‘å€‘å‰µå»ºäº†ä¸€å€‹[æ“´å±•åˆ—è¡¨](https://github.com/sayakpaul/hf-codegen/blob/f659eba76f07e622873211e5b975168b634e6c22/data/prepare_dataset.py#L17C1-L49C68)ä¾†éæ¿¾æ‰å®ƒå€‘ã€‚ç‚ºäº†è§£æ Jupyter Notebooks ä»¥å¤–çš„ç¨‹å¼ç¢¼æ–‡ä»¶ï¼Œæˆ‘å€‘åªéœ€ä½¿ç”¨ "utf-8" ç·¨ç¢¼ã€‚å°æ–¼ Jupyter Notebooksï¼Œæˆ‘å€‘åªè€ƒæ…®ä»£ç¢¼å–®å…ƒ(code cells) è£¡çš„å…§å®¹ã€‚

æˆ‘å€‘ä¹Ÿæ’é™¤äº†æ‰€æœ‰èˆ‡ç¨‹å¼ç¢¼ä¸ç›´æ¥ç›¸é—œçš„æª”æ¡ˆè·¯å¾‘ã€‚å…¶ä¸­åŒ…æ‹¬ï¼š.`git`ã€`__pycache__` å’Œ `xcodeproj`ã€‚

ç‚ºäº†ä¿æŒè©²å…§å®¹çš„åºåˆ—åŒ–ç›¸å°è¨˜æ†¶é«”å‹å¥½ï¼Œæˆ‘å€‘ä½¿ç”¨äº†é€²è¡Œäº†åˆ†å¡Šå’Œä½¿ç”¨ [feather æ ¼å¼](https://arrow.apache.org/docs/python/feather.html#:~:text=Feather%20is%20a%20portable%20file,Python%20(pandas)%20and%20R.)ä¾†åºåˆ—åŒ–ã€‚è«‹åƒé–±æ­¤[è…³æœ¬](https://github.com/sayakpaul/hf-codegen/blob/main/data/prepare_dataset.py)ä»¥äº†è§£å®Œæ•´çš„å¯¦ä½œã€‚

æœ€çµ‚çš„[hf-codegen-v2 è³‡æ–™é›†](https://huggingface.co/datasets/sayakpaul/hf-codegen-v2)å¯åœ¨ Hub ä¸Šæ‰¾åˆ°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![](./personal-copilot/hf-stack-full.png)

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å€‘è€ƒæ…®äº†åŸºæ–¼ stargazer çš„å‰ 10 å€‹ Hugging Face å…¬å…±å„²å­˜åº«ã€‚å®ƒå€‘æ˜¯ï¼š

- 'transformers'
- 'pytorch-image-models'
- 'datasets'
- 'diffusers'
- 'peft'
- 'tokenizers'
- 'accelerate'
- 'text-generation-inference'
- 'chat-ui'
- 'deep-rl-class'

é€™æ˜¯æˆ‘å€‘ç”¨ä¾†ç”¢ç”Ÿæ­¤è³‡æ–™é›†çš„[ç¨‹å¼ç¢¼](https://github.com/pacman100/DHS-LLM-Workshop/tree/main/personal_copilot/dataset_generation)ï¼Œé€™æ˜¯ Hub ä¸­çš„[è³‡æ–™é›†](https://huggingface.co/datasets/smangrul/hf-stack-v1)ã€‚

![](./personal-copilot/hf-stack-v1.png)

ç‚ºäº†é™ä½å°ˆæ¡ˆè¤‡é›œåº¦ï¼Œæˆ‘å€‘æ²’æœ‰è€ƒæ…®è³‡æ–™é›†çš„å»é‡ã€‚å¦‚æœæ‚¨æœ‰èˆˆè¶£åœ¨ç”Ÿç”¢æ‡‰ç”¨ç¨‹å¼ä¸­æ‡‰ç”¨é‡è¤‡è³‡æ–™åˆªé™¤æŠ€è¡“ï¼Œé€™ç¯‡éƒ¨è½æ ¼æ–‡ç« æ˜¯é—œæ–¼ code LLMs æ¡ˆä¾‹çš„å„ªç§€åƒè€ƒè³‡æºã€‚

## å¾®èª¿ Personal Co-Pilot

åœ¨æœ¬ç¯€ä¸­ï¼Œæˆ‘å€‘å°‡å±•ç¤ºå¦‚ä½•å¾®èª¿ä»¥ä¸‹æ¨¡å‹ï¼š[`bigcode/starcoder`](https://hf.co/bigcode/starcoder)ï¼ˆ15.5B åƒæ•¸ï¼‰ã€[`bigcode/starcoderbase-1b`](https://hf.co/bigcode/starcoderbase-1b)ï¼ˆ1B åƒæ•¸ï¼‰ã€[`Deci/DeciCoder-1b`](https://hf.co/Deci/DeciCoder-1b)ï¼ˆ1B åƒæ•¸ï¼‰ã€‚æˆ‘å€‘å°‡ä½¿ç”¨ä¸€å° A100 40GB Colab ç­†è¨˜æœ¬ï¼Œä¸¦ä½¿ç”¨ ğŸ¤— PEFTï¼ˆåƒæ•¸é«˜æ•ˆå¾®èª¿ï¼‰é€²è¡Œæ‰€æœ‰å¯¦é©—ã€‚æ­¤å¤–ï¼Œæˆ‘å€‘å°‡å±•ç¤ºå¦‚ä½•ä½¿ç”¨ ğŸ¤— Accelerate çš„ FSDP æ•´åˆåœ¨å…·æœ‰ 8 å€‹ A100 80GB GPU çš„æ©Ÿå™¨ä¸Šå®Œå…¨å¾®èª¿ bigcode/starcoderï¼ˆ15.5B åƒæ•¸ï¼‰ã€‚è¨“ç·´ç›®æ¨™æ˜¯ [fill in the middleï¼ˆFIMï¼‰](https://arxiv.org/abs/2207.14255)ï¼Œå…¶ä¸­è¨“ç·´åºåˆ—çš„éƒ¨åˆ†å…§å®¹è¢«ç§»å‹•åˆ°æœ«å°¾ï¼Œä¸¦ä¸”å°é‡æ–°æ’åºçš„åºåˆ—é€²è¡Œè‡ªå›æ­¸é æ¸¬ã€‚

ç‚ºä»€éº¼é¸æ“‡PEFT? é€²è¡Œå®Œå…¨å¾®èª¿çš„æˆæœ¬å¾ˆé«˜ã€‚è®“æˆ‘å€‘ç”¨ä¸€äº›æ•¸å­—ä¾†æ­£ç¢ºçœ‹å¾…äº‹æƒ…ï¼š

å®Œå…¨å¾®èª¿æ‰€éœ€çš„æœ€å° GPU è¨˜æ†¶é«”ï¼š

- æ¬Šé‡ï¼š2 bytesï¼ˆæ··åˆç²¾æº–åº¦è¨“ç·´ï¼‰
- æ¬Šé‡æ¢¯åº¦ï¼š2 bytes
- ä½¿ç”¨ Adam æ™‚çš„æœ€ä½³åŒ–å™¨ç‹€æ…‹ï¼š4 bytes æ–¼åŸå§‹ FP32 æ¬Šé‡ + 8 bytes ç”¨æ–¼ç¬¬ä¸€å’Œç¬¬äºŒçŸ©ä¼°è¨ˆ
- æ·»åŠ æ‰€æœ‰ä¸Šè¿°å…§å®¹çš„æ¯å€‹åƒæ•¸çš„æˆæœ¬ï¼šæ¯å€‹åƒæ•¸ 16 bytes
- 15.5B æ¨¡å‹ -> 248GB GPU å…§å­˜ï¼Œç”šè‡³ç„¡éœ€è€ƒæ…®å­˜å„²ä¸­é–“æ¿€æ´»çš„å·¨å¤§å…§å­˜è¦æ±‚ -> è‡³å°‘éœ€è¦ 4X A100 80GB GPU

ç”±æ–¼ç¡¬é«”è¦æ±‚å¾ˆé«˜ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨ [QLoRA](https://arxiv.org/abs/2305.14314) é€²è¡Œåƒæ•¸é«˜æ•ˆçš„å¾®èª¿ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨ [QLoRA](https://arxiv.org/abs/2305.14314) å¾®èª¿ StarCoder çš„æœ€ä½ GPU è¨˜æ†¶é«”éœ€æ±‚ï¼š

> å¯è¨“ç·´åƒæ•¸ï¼š110,428,160 || æ‰€æœ‰åƒæ•¸ï¼š15,627,884,544 || å¯è¨“ç·´ï¼…ï¼š0.7066097761926236

- åŸºæœ¬æ¨¡å‹æ¬Šé‡ï¼š0.5 byte * 15.51B å‡çµåƒæ•¸ = 7.755 GB
- é©é…å™¨æ¬Šé‡ï¼š2 bytes * 0.11B å¯è¨“ç·´åƒæ•¸ = 0.22GB
- æ¬Šé‡æ¢¯åº¦ï¼š2 bytes * 0.11B å¯è¨“ç·´åƒæ•¸ = 0.12GB
- ä½¿ç”¨ Adam æ™‚çš„æœ€ä½³åŒ–å™¨ç‹€æ…‹ï¼š4 byes * 0.11B å¯è¨“ç·´åƒæ•¸ * 3 = 1.32GB
- åŠ ç¸½ä¸Šè¿°å°æ–¼è¨˜æ†¶é«”çš„æ‰€æœ‰å…§å®¹ -> 9.51 GB ~ 10GB -> éœ€è¦ 1 å€‹ A100 40GB GPUã€‚ä½¿ç”¨ A100 40GB GPU çš„åŸå› æ˜¯ï¼Œè¨“ç·´æ™‚é•·åºåˆ—é•·åº¦ç‚º 2048 ä¸”æ‰¹é‡å¤§å°ç‚º 4 çš„ä¸­é–“æ¿€æ´»æœƒå°è‡´æ›´é«˜çš„è¨˜æ†¶é«”éœ€æ±‚ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼Œæ‰€éœ€çš„ GPU è¨˜æ†¶é«”ç‚º 26GBï¼ŒA100 40GB GPU å¯ä»¥å®¹ç´ã€‚æ­¤å¤–ï¼ŒA100 GPU èˆ‡ Flash Attention 2 å…·æœ‰æ›´å¥½çš„å…¼å®¹æ€§ã€‚

åœ¨ä¸Šé¢çš„è¨ˆç®—ä¸­ï¼Œæˆ‘å€‘æ²’æœ‰è€ƒæ…®ä¸­é–“æ¿€æ´»æª¢æŸ¥é»æ‰€éœ€çš„å…§å­˜ï¼Œè©²å…§å­˜ç›¸ç•¶å¤§ã€‚æˆ‘å€‘åˆ©ç”¨ Flash Attention V2 å’Œæ¢¯åº¦æª¢æŸ¥é»ä¾†è§£æ±ºé€™å€‹å•é¡Œã€‚

- å°æ–¼ QLoRA ä»¥åŠ Flash attention V2 å’Œæ¢¯åº¦æª¢æŸ¥é»ï¼Œæ¨¡å‹åœ¨å–®ä¸€ A100 40GB GPU ä¸Šä½”ç”¨çš„ç¸½è¨˜æ†¶é«”ç‚º 26 GBï¼Œæ‰¹æ¬¡å¤§å°ç‚º 4ã€‚
- å°æ–¼ä½¿ç”¨ FSDP ä»¥åŠ Flash Attention V2 å’Œæ¢¯åº¦æª¢æŸ¥é»é€²è¡Œå®Œå…¨å¾®èª¿ï¼Œæ¯å€‹ GPU ä½”ç”¨çš„è¨˜æ†¶é«”ç¯„åœåœ¨ 70 GB åˆ° 77.6 GB ä¹‹é–“ï¼Œper_gpu_batch_size ç‚º 1ã€‚

è«‹åƒé–± [model-memory-usage](https://huggingface.co/spaces/hf-accelerate/model-memory-usage) æƒ…æ³ï¼Œè¼•é¬†è¨ˆç®—åœ¨ ğŸ¤— Hugging Face Hub ä¸Šè¨—ç®¡çš„æ¨¡å‹ä¸Šè¨“ç·´å’ŒåŸ·è¡Œå¤§æ¨¡å‹æ¨ç†æ‰€éœ€çš„ vRAM é‡ã€‚

## å®Œæ•´å¾®èª¿

æˆ‘å€‘å°‡äº†è§£å¦‚ä½•ä½¿ç”¨ PyTorch å…¨åˆ†ç‰‡è³‡æ–™ä¸¦è¡Œ (FSDP) æŠ€è¡“åœ¨ 8 å€‹ A100 80GB GPU ä¸Šå° bigcode/starcoderï¼ˆ15B åƒæ•¸ï¼‰é€²è¡Œå…¨é¢å¾®èª¿ã€‚æœ‰é—œ FSDP çš„æ›´å¤šä¿¡æ¯ï¼Œè«‹åƒé–±[ä½¿ç”¨ PyTorch FSDP å¾®èª¿ Llama 2 70B](https://huggingface.co/blog/ram-efficient-pytorch-fsdp) å’Œ[ä½¿ç”¨ PyTorch å…¨åˆ†ç‰‡è³‡æ–™ä¸¦è¡ŒåŠ é€Ÿå¤§å‹æ¨¡å‹è¨“ç·´](https://huggingface.co/blog/pytorch-fsdp)ã€‚

**è³‡æº**

- Codebase: [é€£çµ](https://github.com/pacman100/DHS-LLM-Workshop/tree/main/personal_copilot/training)ã€‚å®ƒä½¿ç”¨ Transformers æœ€è¿‘æ–°å¢çš„ Flash Attention V2 æ”¯æ´ã€‚
- FSDP Config: [fsdp_config.yaml](https://github.com/pacman100/DHS-LLM-Workshop/blob/main/personal_copilot/training/configs/fsdp_config.yaml)
- Model: [bigcode/stacoder](https://huggingface.co/bigcode/starcoder)
- Dataset: [smangrul/hf-stack-v1](https://huggingface.co/datasets/smangrul/hf-stack-v1)
- Fine-tuned Model: [smangrul/peft-lora-starcoder15B-v2-personal-copilot-A100-40GB-colab](https://huggingface.co/smangrul/peft-lora-starcoder15B-v2-personal-copilot-A100-40GB-colab)

é€é [run_fsdp.sh](https://github.com/pacman100/DHS-LLM-Workshop/blob/main/personal_copilot/training/run_fsdp.sh) ä¾†å•Ÿå‹•è¨“ç·´çš„æŒ‡ä»¤ã€‚

```bash
accelerate launch --config_file "configs/fsdp_config.yaml"  train.py \
    --model_path "bigcode/starcoder" \
    --dataset_name "smangrul/hf-stack-v1" \
    --subset "data" \
    --data_column "content" \
    --split "train" \
    --seq_length 2048 \
    --max_steps 2000 \
    --batch_size 1 \
    --gradient_accumulation_steps 2 \
    --learning_rate 5e-5 \
    --lr_scheduler_type "cosine" \
    --weight_decay 0.01 \
    --num_warmup_steps 30 \
    --eval_freq 100 \
    --save_freq 500 \
    --log_freq 25 \
    --num_workers 4 \
    --bf16 \
    --no_fp16 \
    --output_dir "starcoder-personal-copilot-A100-40GB-colab" \
    --fim_rate 0.5 \
    --fim_spm_rate 0.5 \
    --use_flash_attn
```

ç¸½è¨“ç·´æ™‚é–“ç‚º9å°æ™‚ã€‚æ ¹æ“š lambdalabs è¨ˆç®— 8 å€‹ A100 80GB GPU çš„æˆæœ¬ç‚º 12.00 ç¾å…ƒ/å°æ™‚ï¼Œç¸½æˆæœ¬ç‚º 108 ç¾å…ƒã€‚

## PEFT

æ¥ä¸‹ä¾†æˆ‘å€‘å°‡äº†è§£å¦‚ä½•ä½¿ç”¨ QLoRA ä½¿ç”¨ ğŸ¤— PEFT åœ¨å–®ä¸€ A100 40GB GPU ä¸Šå¾®èª¿ å··`bigcode/starcoder`ï¼ˆ15B åƒæ•¸ï¼‰ã€‚æœ‰é—œ QLoRA å’Œ PEFT æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ï¼Œè«‹åƒé–± [Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes) å’Œ [ğŸ¤— PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware](https://huggingface.co/blog/peft)ã€‚

**è³‡æº**

- Codebase: [link](https://github.com/pacman100/DHS-LLM-Workshop/tree/main/personal_copilot/training)ã€‚å®ƒä½¿ç”¨ Transformers æœ€è¿‘æ–°å¢çš„ Flash Attention V2 æ”¯æ´ã€‚
- Colab notebook: [link](https://colab.research.google.com/drive/1Tz9KKgacppA4S6H4eo_sw43qEaC9lFLs?usp=sharing)ã€‚ç¢ºä¿é¸æ“‡å…·æœ‰é«˜ RAM è¨­å®šçš„ A100 GPUã€‚
- Model: [bigcode/stacoder](https://huggingface.co/bigcode/starcoder)
- Dataset: [smangrul/hf-stack-v1](https://huggingface.co/datasets/smangrul/hf-stack-v1)
- QLoRA Fine-tuned Model: [smangrul/peft-lora-starcoder15B-v2-personal-copilot-A100-40GB-colab](https://huggingface.co/smangrul/peft-lora-starcoder15B-v2-personal-copilot-A100-40GB-colab)

å•Ÿå‹•è¨“ç·´çš„å‘½ä»¤åœ¨ [run_peft.sh](https://github.com/pacman100/DHS-LLM-Workshop/blob/main/personal_copilot/training/run_peft.sh) ä¸­ã€‚ç¸½è¨“ç·´æ™‚é–“ç‚º12.5å°æ™‚ã€‚æ ¹æ“š lambdalabsï¼Œä»¥ 1.10 ç¾å…ƒ/å°æ™‚çš„æˆæœ¬è¨ˆç®—ï¼Œç¸½æˆæœ¬ç‚º 13.75 ç¾å…ƒã€‚é‚£å°±ç›¸ç•¶ä¸éŒ¯äº†ğŸš€ï¼å°±æˆæœ¬è€Œè¨€ï¼Œå®ƒæ¯”å®Œå…¨å¾®èª¿çš„æˆæœ¬ä½7.8å€ã€‚

## æ¯”è¼ƒ

ä¸‹åœ–é¡¯ç¤ºäº† QLoRA èˆ‡å®Œå…¨å¾®èª¿çš„è©•ä¼°æå¤±ã€è¨“ç·´æå¤±å’Œå­¸ç¿’ç‡èª¿åº¦ç¨‹åºã€‚æˆ‘å€‘è§€å¯Ÿåˆ°ï¼Œèˆ‡ QLoRA ç›¸æ¯”ï¼Œå®Œå…¨å¾®èª¿æœƒå°è‡´æå¤±ç•¥ä½ä¸”æ”¶æ–‚é€Ÿåº¦æ›´å¿«ã€‚ pef å¾®èª¿çš„å­¸ç¿’ç‡æ¯” full å¾®èª¿çš„å­¸ç¿’ç‡é«˜ 10 å€ã€‚

![](./personal-copilot/full_finetuning_vs_qlora.png)

ç‚ºäº†ç¢ºä¿æˆ‘å€‘çš„ QLoRA æ¨¡å‹ä¸æœƒå°è‡´ç½é›£æ€§éºå¿˜ï¼Œæˆ‘å€‘åœ¨å…¶ä¸Šé‹è¡Œäº† Python Human Evalã€‚ä»¥ä¸‹æ˜¯æˆ‘å€‘å¾—åˆ°çš„çµæœã€‚ `Pass@1` è¡¡é‡å®Œæˆçš„é€šéç‡ï¼Œåƒ…è€ƒæ…®æ¯å€‹å•é¡Œç”¢ç”Ÿçš„å–®ä¸€å€™é¸ä»£ç¢¼ã€‚æˆ‘å€‘å¯ä»¥è§€å¯Ÿåˆ°ï¼ŒåŸºæœ¬ `bigcode/starcoder`ï¼ˆ15B åƒæ•¸ï¼‰å’Œå¾®èª¿ PEFT æ¨¡å‹ `smangrul/peft-lora-starcoder15B-v2-personal-copilot-A100-40GB-colab` åœ¨ humaneval-python ä¸Šçš„è¡¨ç¾ç›¸ç•¶ã€‚


|Model	|Pass@1|
|bigcode/starcoder	|33.57|
|smangrul/peft-lora-starcoder15B-v2-personal-copilot-A100-40GB-colab	|33.37|

ç¾åœ¨è®“æˆ‘å€‘ä¾†çœ‹ä¸€äº›å®šæ€§æ¨£æœ¬ã€‚åœ¨æˆ‘å€‘çš„æ‰‹å‹•åˆ†æä¸­ï¼Œæˆ‘å€‘æ³¨æ„åˆ° QLoRA å°è‡´äº†è¼•å¾®çš„éåº¦æ“¬åˆï¼Œå› æ­¤æˆ‘å€‘é€é PEFT çš„ `add_weighted_adapter` utility ç¨‹å¼å‰µå»ºæ¬Šé‡ç‚º 0.8 çš„æ–°åŠ æ¬Šé©é…å™¨ä¾†é™ä½å…¶æ¬Šé‡ã€‚

æˆ‘å€‘å°‡çœ‹å…©å€‹ç¨‹å¼ç¢¼å¡«å……ç¯„ä¾‹ï¼Œå…¶ä¸­æ¨¡å‹çš„ä»»å‹™æ˜¯å¡«å…¥ `<FILL_ME>` ä½”ä½ç¬¦è¡¨ç¤ºçš„éƒ¨åˆ†ã€‚æˆ‘å€‘å°‡è€ƒæ…®å¡«æ»¿ä¾†è‡ª GitHub Copilotã€QLoRA å¾®èª¿æ¨¡å‹å’Œå®Œæ•´å¾®èª¿æ¨¡å‹çš„è£œå…¨ã€‚

![](./personal-copilot/qlora_vs_finetune_1.png)

**Qualitative Example 1**

åœ¨ä¸Šé¢çš„ç¯„ä¾‹ä¸­ï¼ŒGitHub Copilot çš„è£œå…¨æ˜¯æ­£ç¢ºçš„ï¼Œä½†æ²’æœ‰å¤ªå¤§å¹«åŠ©ã€‚å¦ä¸€æ–¹é¢ï¼ŒQLoRA çš„è£œå…¨å’Œå®Œå…¨å¾®èª¿çš„æ¨¡å‹æ­£ç¢ºåœ°ç”¨å¿…è¦çš„åƒæ•¸å¡«å……äº†æ•´å€‹å‡½æ•¸å‘¼å«ã€‚ç„¶è€Œï¼Œä»–å€‘ä¹‹å¾Œä¹Ÿå¢åŠ äº†æ›´å¤šçš„å™ªéŸ³ã€‚é€™å¯ä»¥é€éå¾Œè™•ç†æ­¥é©Ÿä¾†æ§åˆ¶ï¼Œä»¥å°‡å®Œæˆé™åˆ¶ç‚ºå³æ‹¬è™Ÿæˆ–æ–°è¡Œã€‚è«‹æ³¨æ„ï¼ŒQLoRA å’Œå®Œå…¨å¾®èª¿æ¨¡å‹éƒ½æœƒç”¢ç”Ÿé¡ä¼¼å“è³ªçš„çµæœã€‚

![](./personal-copilot/qlora_vs_finetune_2.png)

**Qualitative Example 2**

åœ¨ä¸Šé¢çš„ç¬¬äºŒå€‹ç¯„ä¾‹ä¸­ï¼ŒGitHub Copilot æ²’æœ‰çµ¦å‡ºä»»ä½•è£œå…¨è³‡è¨Šã€‚é€™å¯èƒ½æ˜¯å› ç‚º ğŸ¤— PEFT æ˜¯ä¸€å€‹æ–°å‡½å¼åº«ï¼Œå°šæœªæˆç‚º Copilot è¨“ç·´è³‡æ–™çš„ä¸€éƒ¨åˆ†ï¼Œè€Œé€™æ­£æ˜¯æˆ‘å€‘è©¦åœ–è§£æ±ºçš„å•é¡Œé¡å‹ã€‚å¦ä¸€æ–¹é¢ï¼ŒQLoRA çš„è£œå…¨å’Œå®Œå…¨å¾®èª¿çš„æ¨¡å‹æ­£ç¢ºåœ°ç”¨å¿…è¦çš„åƒæ•¸å¡«å……äº†æ•´å€‹å‡½æ•¸å‘¼å«ã€‚

å†æ¬¡è«‹æ³¨æ„ï¼ŒQLoRA å’Œå®Œå…¨å¾®èª¿çš„æ¨¡å‹éƒ½æä¾›äº†é¡ä¼¼çš„å“è³ªã€‚ [Full_Fintuned_StarCoder_Inference.ipynb](https://github.com/pacman100/DHS-LLM-Workshop/blob/main/personal_copilot/inference/Full_Finetuned_StarCoder_Inference.ipynb) å’Œ [PEFT_StarCoder_Inference.ipynb](https://github.com/pacman100/DHS-LLM-Workshop/blob/main/personal_copilot/inference/PEFT_StarCoder_Inference.ipynb) åˆ†åˆ¥æä¾›äº†å®Œæ•´å¾®èª¿æ¨¡å‹å’Œ peft æ¨¡å‹çš„å„ç¨®ç¯„ä¾‹çš„æ¨ç†ç¨‹å¼ç¢¼ã€‚

å› æ­¤ï¼Œæˆ‘å€‘å¯ä»¥è§€å¯Ÿåˆ°å…©å€‹è®Šé«”çš„æ¨¡å‹éƒ½ç¬¦åˆé æœŸã€‚é©šäººï¼ ğŸš€

## å¦‚ä½•åœ¨ VS Code ä¸­ä½¿ç”¨å®ƒï¼Ÿ

æ‚¨å¯ä»¥ä½¿ç”¨ [ğŸ¤— llm-vscode](https://marketplace.visualstudio.com/items?itemName=HuggingFace.huggingface-vscode) ä¾†åœ¨ VS Code ä¸­è¼•é¬†é…ç½®è‡ªè¨‚ç¨‹å¼ç¢¼å®Œæˆ LLMã€€çš„æ“´å……ï¼Œä¸¦é€é [ğŸ¤— æ¨ç†ç«¯é»](https://ui.endpoints.huggingface.co/)è¨—ç®¡æ¨¡å‹ã€‚æˆ‘å€‘å°‡å®Œæˆä¸‹é¢æ‰€éœ€çš„æ­¥é©Ÿã€‚æ‚¨å¯ä»¥åœ¨æ¨ç†ç«¯é»æ–‡ä»¶ä¸­äº†è§£æœ‰é—œéƒ¨ç½²ç«¯é»çš„æ›´å¤šè©³ç´°è³‡è¨Šã€‚

### è¨­å®šæ¨ç†ç«¯é»

ä»¥ä¸‹æ˜¯è¢å¹•æˆªåœ–ï¼Œå…¶ä¸­åŒ…å«æˆ‘å€‘å»ºç«‹è‡ªè¨‚æ¨ç†ç«¯é»æ‰€éµå¾ªçš„æ­¥é©Ÿã€‚æˆ‘å€‘ä½¿ç”¨ QLoRA æ¨¡å‹ï¼ŒåŒ¯å‡ºç‚ºå…¨å°ºå¯¸åˆä½µæ¨¡å‹ï¼Œå¯ä»¥è¼•é¬†è¼‰å…¥åˆ° Transformer ä¸­ã€‚

![](./personal-copilot/inference_endpoint_2.png)

### è¨­å®š VS ä»£ç¢¼æ“´å±•

åªéœ€æŒ‰ç…§[å®‰è£æ­¥é©Ÿ](https://github.com/huggingface/llm-vscode#installation)æ“ä½œå³å¯ã€‚åœ¨è¨­å®šä¸­ï¼Œå–ä»£ä¸‹æ–¹æ¬„ä½ä¸­çš„ç«¯é»ï¼Œä½¿å…¶æŒ‡å‘æ‚¨éƒ¨ç½²çš„ HF æ¨ç†ç«¯é»ã€‚

![](./personal-copilot/vs_code_endpoint.png)

ç”¨æ³•å¦‚ä¸‹ï¼š

![](./personal-copilot/vs_code_completion_usage.png)

## å¾®èª¿æ‚¨è‡ªå·±çš„ Code Chat Assistant

åˆ°ç›®å‰ç‚ºæ­¢ï¼Œæˆ‘å€‘è¨“ç·´çš„æ¨¡å‹è¢«å°ˆé–€è¨“ç·´ç‚ºç¨‹å¼ç¢¼å®Œæˆä»»å‹™çš„å€‹äººå‰¯é§•é§›ã€‚ä»–å€‘æ²’æœ‰æ¥å—éé€²è¡Œå°è©±æˆ–å›ç­”å•é¡Œçš„è¨“ç·´ã€‚ `Octocoder` å’Œ `StarChat` æ˜¯æ­¤é¡æ¨¡å‹çš„å¾ˆå¥½çš„ä¾‹å­ã€‚æœ¬ç¯€ç°¡è¦ä»‹ç´¹å¦‚ä½•å¯¦ç¾é€™ä¸€ç›®æ¨™ã€‚

**è³‡æº**

- Codebase: [link](https://github.com/pacman100/DHS-LLM-Workshop/tree/main/code_assistant/training)ã€‚å®ƒä½¿ç”¨ Transformers æœ€è¿‘æ–°å¢çš„ Flash Attention V2 æ”¯æ´ã€‚
- Colab notebook: [link](https://colab.research.google.com/drive/1XFyePK-3IoyX81RM94JO73CcIZtAU4i4?usp=sharing)ã€‚ç¢ºä¿é¸æ“‡å…·æœ‰é«˜ RAM è¨­å®šçš„ A100 GPUã€‚
- Model: [bigcode/stacoderplus](https://huggingface.co/bigcode/starcoderplus)
- Dataset: [smangrul/code-chat-assistant-v1](https://huggingface.co/datasets/smangrul/code-chat-assistant-v1)ã€‚ LIMA+GUANACO çš„æ··åˆï¼Œä¸¦ä»¥å¯ç«‹å³è¨“ç·´çš„æ ¼å¼é€²è¡Œé©ç•¶çš„æ•¸æ“šæ ¼å¼åŒ–ã€‚
- Trained Model: [smangrul/peft-lora-starcoderplus-chat-asst-A100-40GB-colab](https://huggingface.co/smangrul/peft-lora-starcoderplus-chat-asst-A100-40GB-colab)

## LoRA ä¹‹èˆ

å¦‚æœæ‚¨æ›¾å˜—è©¦ä½¿ç”¨ Stable Diffusion æ¨¡å‹å’Œ LoRA ä¾†è£½ä½œè‡ªå·±çš„ Dreambooth æ¨¡å‹ï¼Œé‚£éº¼æ‚¨å¯èƒ½ç†Ÿæ‚‰å°‡ä¸åŒçš„ LoRA èˆ‡ä¸åŒæ¬Šé‡ç›¸çµåˆçš„æ¦‚å¿µï¼Œå³ä½¿ç”¨å…·æœ‰èˆ‡è¨“ç·´æ™‚ä¸åŒçš„åŸºç¤æ¨¡å‹çš„ LoRA æ¨¡å‹ã€‚åœ¨æ–‡å­—/ç¨‹å¼ç¢¼é ˜åŸŸï¼Œé€™ä»ç„¶æ˜¯æœªé–‹ç™¼çš„é ˜åŸŸã€‚æˆ‘å€‘åœ¨é€™æ–¹é¢é€²è¡Œäº†å¯¦é©—ï¼Œä¸¦è§€å¯Ÿåˆ°äº†éå¸¸æœ‰å¸Œæœ›çš„ç™¼ç¾ã€‚ä½ æº–å‚™å¥½äº†å—ï¼Ÿæˆ‘å€‘èµ°å§ï¼ ğŸš€