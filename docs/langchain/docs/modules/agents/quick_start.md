# Quickstart

ç‚ºäº†æ›´å¥½åœ°ç†è§£ agent frameworkï¼Œè®“æˆ‘å€‘å»ºç«‹ä¸€å€‹å…·æœ‰å…©ç¨®å·¥å…·çš„ä»£ç†ï¼šä¸€ç¨®ç”¨æ–¼ç·šä¸ŠæŸ¥æ‰¾ï¼Œå¦ä¸€ç¨®ç”¨æ–¼æŸ¥æ‰¾æˆ‘å€‘è¼‰å…¥åˆ°ç´¢å¼•ä¸­çš„ç‰¹å®šè³‡æ–™ã€‚

![](./assets/lanchain_agents_architecture.png)

## å®šç¾©å·¥å…·

æˆ‘å€‘é¦–å…ˆéœ€è¦å‰µå»ºæˆ‘å€‘æƒ³è¦ä½¿ç”¨çš„å·¥å…·ã€‚æˆ‘å€‘å°‡ä½¿ç”¨å…©å€‹å·¥å…·ï¼šTavilyï¼ˆç”¨æ–¼ç·šä¸Šæœå°‹ï¼‰ï¼Œç„¶å¾Œæ˜¯æˆ‘å€‘å°‡å»ºç«‹çš„æœ¬åœ°ç´¢å¼•çš„æª¢ç´¢å™¨ã€‚

### Tavily

åœ¨ LangChain ä¸­æœ‰ä¸€å€‹å…§å»ºçš„å·¥å…·ï¼Œå¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨ Tavily æœå°‹å¼•æ“ä½œç‚ºå·¥å…·ã€‚è«‹æ³¨æ„ï¼Œé€™éœ€è¦ä¸€å€‹ API é‡‘é‘° - ä»–å€‘æœ‰ä¸€å€‹å…è²»å¥—é¤ï¼Œä½†å¦‚æœæ‚¨æ²’æœ‰æˆ–ä¸æƒ³å»ºç«‹ä¸€å€‹ï¼Œæ‚¨å¯ä»¥éš¨æ™‚å¿½ç•¥æ­¤æ­¥é©Ÿã€‚

å»ºç«‹ API é‡‘é‘°å¾Œï¼Œæ‚¨éœ€è¦å°‡å…¶åŒ¯å‡ºç‚ºç’°å¢ƒè®Šæ•¸ï¼š

```bash
export TAVILY_API_KEY="..."
```

```python
from langchain_community.tools.tavily_search import TavilySearchResults

search = TavilySearchResults()

search.invoke("what is the weather in SF")
```

åŸ·è¡Œçµæœ:

```bash
[{'url': 'https://www.metoffice.gov.uk/weather/forecast/9q8yym8kr',
  'content': 'Thu 11 Jan Thu 11 Jan Seven day forecast for San Francisco  San Francisco (United States of America) weather Find a forecast  Sat 6 Jan Sat 6 Jan Sun 7 Jan Sun 7 Jan Mon 8 Jan Mon 8 Jan Tue 9 Jan Tue 9 Jan Wed 10 Jan Wed 10 Jan Thu 11 Jan  Find a forecast Please choose your location from the nearest places to : Forecast days Today Today Sat 6 Jan Sat 6 JanSan Francisco 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV ... (11 January 2024) Time 00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 ... Oakland Int. 11.5 miles; San Francisco International 11.5 miles; Corte Madera 12.3 miles; Redwood City 23.4 miles;'},
 {'url': 'https://www.latimes.com/travel/story/2024-01-11/east-brother-light-station-lighthouse-california',
  'content': "May 18, 2023  Jan. 4, 2024 Subscribe for unlimited accessSite Map Follow Us MORE FROM THE L.A. TIMES  Jan. 8, 2024 Travel & Experiences This must be Elysian Valley (a.k.a. Frogtown) Jan. 5, 2024 Food  June 30, 2023The East Brother Light Station in the San Francisco Bay is not a destination for everyone. ... Jan. 11, 2024 3 AM PT ... Champagne and hors d'oeuvres are served in late afternoon â€” outdoors if ..."}]
```

### Retriever

æˆ‘å€‘é‚„å°‡æ ¹æ“šæˆ‘å€‘è‡ªå·±çš„ä¸€äº›æ•¸æ“šå‰µå»ºä¸€å€‹çŸ¥è­˜æª¢ç´¢å™¨(retriever)ã€‚

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

loader = WebBaseLoader("https://docs.smith.langchain.com/overview")

docs = loader.load()

documents = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200
).split_documents(docs)

vector = FAISS.from_documents(documents, OpenAIEmbeddings())

retriever = vector.as_retriever()
```


ç¾åœ¨æˆ‘å€‘å·²ç¶“æ§‹å»ºäº†æˆ‘å€‘å°‡é€²è¡Œæª¢ç´¢çš„ç´¢å¼•ï¼Œæˆ‘å€‘å¯ä»¥è¼•é¬†åœ°å°‡å…¶è®Šæˆä¸€å€‹å·¥å…·ï¼ˆè®“ä»£ç†ç¨‹å¼å¯æ­£ç¢ºä½¿ç”¨å®ƒæ‰€éœ€çš„æ ¼å¼ï¼‰

```python
from langchain.tools.retriever import create_retriever_tool

retriever_tool = create_retriever_tool(
    retriever,
    "langsmith_search",
    "Search for information about LangSmith. For any questions about LangSmith, you must use this tool!",
)
```

### Tool

ç¾åœ¨æˆ‘å€‘å·²ç¶“å‰µå»ºäº†å…©è€…ï¼Œæˆ‘å€‘å¯ä»¥å»ºç«‹å°‡åœ¨ä¸‹æ¸¸ä½¿ç”¨çš„å·¥å…·æ¸…å–®ã€‚

```python
tools = [search, retriever_tool]
```

## å‰µå»º Agent

ç¾åœ¨æˆ‘å€‘å·²ç¶“å®šç¾©äº†å·¥å…·ï¼Œæˆ‘å€‘å¯ä»¥å»ºç«‹ä»£ç†(agent)ã€‚æˆ‘å€‘å°‡ä½¿ç”¨ OpenAI Functions agent - æœ‰é—œæ­¤é¡ä»£ç†ä»¥åŠå…¶ä»–é¸é …çš„æ›´å¤šä¿¡æ¯ï¼Œè«‹åƒé–±[æœ¬æŒ‡å—](https://python.langchain.com/docs/modules/agents/agent_types)ã€‚

é¦–å…ˆï¼Œæˆ‘å€‘é¸æ“‡æˆ‘å€‘æƒ³è¦æŒ‡å°ä»£ç†äººçš„ LLMã€‚

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
```

æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘é¸æ“‡è¦ç”¨ä¾†æŒ‡å°ä»£ç†äººçš„æç¤ºã€‚

å¦‚æœæ‚¨æƒ³æŸ¥çœ‹æ­¤æç¤ºçš„å…§å®¹ä¸¦æœ‰æ¬Šè¨ªå• LangSmithï¼Œæ‚¨å¯ä»¥è¨ªå•ï¼š

- https://smith.langchain.com/hub/hwchase17/openai-functions-agent

```python
from langchain import hub

# Get the prompt to use - you can modify this!
prompt = hub.pull("hwchase17/openai-functions-agent")


print(prompt.messages)
```

çµæœ:

```bash
[
    SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),
    MessagesPlaceholder(variable_name='chat_history', optional=True),
    HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),
    MessagesPlaceholder(variable_name='agent_scratchpad')]
```

ç¾åœ¨ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨ LLMã€æç¤ºå­—å…ƒå’Œå·¥å…·ä¾†åˆå§‹åŒ–ä»£ç†ç¨‹å¼ã€‚ä»£ç†è² è²¬æ¥æ”¶è¼¸å…¥ä¸¦æ±ºå®šæ¡å–ä»€éº¼æ“ä½œã€‚è‡³é—œé‡è¦çš„æ˜¯ï¼Œä»£ç†ç¨‹å¼ä¸åŸ·è¡Œé€™äº›æ“ä½œ - é€™æ˜¯ç”± `AgentExecutor` å®Œæˆçš„ï¼ˆä¸‹ä¸€æ­¥ï¼‰ã€‚æœ‰é—œå¦‚ä½•æ€è€ƒé€™äº›çµ„ä»¶çš„æ›´å¤šä¿¡æ¯ï¼Œè«‹åƒé–±æˆ‘å€‘çš„[æ¦‚å¿µæŒ‡å—](https://python.langchain.com/docs/modules/agents/concepts)ã€‚

```python
from langchain.agents import create_openai_functions_agent

agent = create_openai_functions_agent(llm, tools, prompt)
```

æœ€å¾Œï¼Œæˆ‘å€‘å°‡ agentï¼ˆå¤§è…¦ï¼‰èˆ‡ AgentExecutor å…§éƒ¨çš„å·¥å…·ï¼ˆå®ƒå°‡é‡è¤‡èª¿ç”¨ä»£ç†ä¸¦åŸ·è¡Œå·¥å…·ï¼‰çµåˆèµ·ä¾†ã€‚æœ‰é—œå¦‚ä½•æ€è€ƒé€™äº›çµ„ä»¶çš„æ›´å¤šä¿¡æ¯ï¼Œè«‹åƒé–±æˆ‘å€‘çš„æ¦‚å¿µæŒ‡å—

```python
from langchain.agents import AgentExecutor

agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
```

## é‹è¡Œ Agent

æˆ‘å€‘ç¾åœ¨å¯ä»¥é‡å°ä¸€äº›æŸ¥è©¢é‹è¡Œä»£ç†ç¨‹å¼ï¼è«‹æ³¨æ„ï¼Œç›®å‰é€™äº›éƒ½æ˜¯ç„¡ç‹€æ…‹æŸ¥è©¢ï¼ˆå®ƒä¸æœƒè¨˜ä½å…ˆå‰çš„äº’å‹•ï¼‰ã€‚

```python
agent_executor.invoke({"input": "hi!"})
```

çµæœ:

```bash
> Entering new AgentExecutor chain...
Hello! How can I assist you today?

> Finished chain.

{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}
```

```python
agent_executor.invoke({"input": "how can langsmith help with testing?"})
```

çµæœ:

```bash


> Entering new AgentExecutor chain...

Invoking: `langsmith_search` with `{'query': 'LangSmith testing'}`


[Document(page_content='LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}), Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}), Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.Weâ€™ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing â€” mirroring the', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}), Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'})]LangSmith can help with testing in several ways. Here are some ways LangSmith can assist with testing:

1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.

2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.

3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.

4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.

For more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).

> Finished chain.

{'input': 'how can langsmith help with testing?',
 'output': 'LangSmith can help with testing in several ways. Here are some ways LangSmith can assist with testing:\n\n1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\n\n2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.\n\n3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.\n\n4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.\n\nFor more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).'}
```


```python
agent_executor.invoke({"input": "whats the weather in sf?"})
```

çµæœ:

```bash


> Entering new AgentExecutor chain...

Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`


[{'url': 'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/', 'content': 'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  Seasonal average climate and temperature of San Francisco in january  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 11-01-2023 50Â°F to 54Â°F. 12-01-2023 50Â°F to 59Â°F. 13-01-2023 54Â°F to ...'}, {'url': 'https://www.latimes.com/travel/story/2024-01-11/east-brother-light-station-lighthouse-california', 'content': "May 18, 2023  Jan. 4, 2024 Subscribe for unlimited accessSite Map Follow Us MORE FROM THE L.A. TIMES  Jan. 8, 2024 Travel & Experiences This must be Elysian Valley (a.k.a. Frogtown) Jan. 5, 2024 Food  June 30, 2023The East Brother Light Station in the San Francisco Bay is not a destination for everyone. ... Jan. 11, 2024 3 AM PT ... Champagne and hors d'oeuvres are served in late afternoon â€” outdoors if ..."}]I'm sorry, I couldn't find the current weather in San Francisco. However, you can check the weather in San Francisco by visiting a reliable weather website or using a weather app on your phone.

> Finished chain.

{'input': 'whats the weather in sf?',
 'output': "I'm sorry, I couldn't find the current weather in San Francisco. However, you can check the weather in San Francisco by visiting a reliable weather website or using a weather app on your phone."}
```

## æ·»åŠ åˆ°è¨˜æ†¶ä¸­

å¦‚å‰æ‰€è¿°ï¼Œè©² agent æ˜¯ç„¡ç‹€æ…‹çš„ã€‚é€™æ„å‘³è‘—å®ƒä¸è¨˜å¾—å…ˆå‰çš„äº’å‹•ã€‚ç‚ºäº†çµ¦å®ƒè¨˜æ†¶ï¼Œæˆ‘å€‘éœ€è¦å‚³éä»¥å‰çš„ `chat_history`ã€‚æ³¨æ„ï¼šç”±æ–¼æˆ‘å€‘ä½¿ç”¨çš„æç¤ºï¼Œå®ƒéœ€è¦è¢«ç¨±ç‚º `chat_history`ã€‚å¦‚æœæˆ‘å€‘ä½¿ç”¨ä¸åŒçš„æç¤ºï¼Œæˆ‘å€‘å¯ä»¥æ›´æ”¹è®Šæ•¸åç¨±

```python
# Here we pass in an empty list of messages for chat_history because it is the first message in the chat
agent_executor.invoke({"input": "hi! my name is bob", "chat_history": []})
```

çµæœ:

```bash
> Entering new AgentExecutor chain...
Hello Bob! How can I assist you today?

> Finished chain.

{'input': 'hi! my name is bob',
 'chat_history': [],
 'output': 'Hello Bob! How can I assist you today?'}
```

æŠŠä¹‹å‰çš„å°è©±ä¿å­˜åœ¨ `chat_history` è®Šæ•¸ä¸­:

```python
from langchain_core.messages import AIMessage, HumanMessage

agent_executor.invoke(
    {
        "chat_history": [
            HumanMessage(content="hi! my name is bob"),
            AIMessage(content="Hello Bob! How can I assist you today?"),
        ],
        "input": "what's my name?",
    }
)
```

çµæœ:

```bash


> Entering new AgentExecutor chain...
Your name is Bob.

> Finished chain.

{'chat_history': [HumanMessage(content='hi! my name is bob'),
  AIMessage(content='Hello Bob! How can I assist you today?')],
 'input': "what's my name?",
 'output': 'Your name is Bob.'}
```

å¦‚æœæˆ‘å€‘æƒ³è‡ªå‹•è¿½è¹¤é€™äº›è¨Šæ¯ï¼Œæˆ‘å€‘å¯ä»¥å°‡å…¶åŒ…è£åœ¨ `RunnableWithMessageHistory` ä¸­ã€‚æœ‰é—œå¦‚ä½•ä½¿ç”¨å®ƒçš„æ›´å¤šä¿¡æ¯ï¼Œè«‹åƒé–±æœ¬æŒ‡å—

```python
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

message_history = ChatMessageHistory()

agent_with_chat_history = RunnableWithMessageHistory(
    agent_executor,
    # This is needed because in most real world scenarios, a session id is needed
    # It isn't really used here because we are using a simple in memory ChatMessageHistory
    lambda session_id: message_history,
    input_messages_key="input",
    history_messages_key="chat_history",
)

agent_with_chat_history.invoke(
    {"input": "hi! I'm bob"},
    # This is needed because in most real world scenarios, a session id is needed
    # It isn't really used here because we are using a simple in memory ChatMessageHistory
    config={"configurable": {"session_id": "<foo>"}},
)
```

çµæœ:

```bash


> Entering new AgentExecutor chain...
Your name is Bob.

> Finished chain.

{'input': "what's my name?",
 'chat_history': [HumanMessage(content="hi! I'm bob"),
  AIMessage(content='Hello Bob! How can I assist you today?')],
 'output': 'Your name is Bob.'}
```

## çµè«–

åœ¨æœ¬å¿«é€Ÿå…¥é–€ä¸­ï¼Œæˆ‘å€‘ä»‹ç´¹å¦‚ä½•å»ºç«‹ä¸€å€‹ç°¡å–®çš„ä»£ç†ç¨‹å¼ã€‚ä»£ç†æ˜¯ä¸€å€‹è¤‡é›œçš„è©±é¡Œï¼Œæœ‰å¾ˆå¤šæ±è¥¿è¦å­¸ç¿’ï¼è¿”å›ä»£ç†ä¸»é é¢ï¼ŒæŸ¥æ‰¾æœ‰é—œæ¦‚å¿µæŒ‡å—ã€ä¸åŒé¡å‹ä»£ç†ã€å¦‚ä½•å»ºç«‹è‡ªè¨‚å·¥å…·ç­‰çš„æ›´å¤šè³‡æºï¼
