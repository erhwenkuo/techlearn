# OpenLLM

ğŸ¦¾ [OpenLLM](https://github.com/bentoml/OpenLLM) æ˜¯ä¸€å€‹ç”¨æ–¼åœ¨ç”Ÿç”¢ä¸­æ“ä½œå¤§å‹èªè¨€æ¨¡å‹ (LLM) çš„é–‹æ”¾å¹³å°ã€‚å®ƒä½¿é–‹ç™¼äººå“¡èƒ½å¤ è¼•é¬†åœ°ä½¿ç”¨ä»»ä½•é–‹æº LLMs é‹è¡Œæ¨ç†ã€éƒ¨ç½²åˆ°é›²ç«¯æˆ–æœ¬åœ°ï¼Œä¸¦æ§‹å»ºå¼·å¤§çš„äººå·¥æ™ºèƒ½æ‡‰ç”¨ç¨‹åºã€‚

## å®‰è£

é€šé [PyPI](https://pypi.org/project/openllm/) å®‰è£ `openllm`

```bash
pip install openllm
```

## æœ¬åœ°å•Ÿå‹• OpenLLM æœå‹™å™¨

è¦å•Ÿå‹• LLM æœå‹™å™¨ï¼Œè«‹ä½¿ç”¨ `openllm start` å‘½ä»¤ã€‚ä¾‹å¦‚ï¼Œè¦å•Ÿå‹• `dolly-v2` æœå‹™å™¨ï¼Œè«‹å¾çµ‚ç«¯(terminal)é‹è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
openllm start dolly-v2
```

è©³ç´°å‘½ä»¤è«‹åƒè€ƒ: [OpenLLM æ¨¡å‹æ”¯æ´](../../../../llm/serving/openllm/models_supported.md)

## Wrapper é¡åˆ¥

é€£æ¥é ç«¯çš„ OpenLLM æœå‹™å™¨å¯¦ä¾‹:

```python
from langchain.llms import OpenLLM

server_url = "http://localhost:3000"  # Replace with remote host if you are running on a remote server
llm = OpenLLM(server_url=server_url)
```

API Reference:

- [OpenLLM](https://api.python.langchain.com/en/latest/llms/langchain.llms.openllm.OpenLLM.html)

### æœ¬åœ° LLM æ¨è«–

æ‚¨é‚„å¯ä»¥é¸æ“‡å¾ç•¶å‰é€²ç¨‹æœ¬åœ°åˆå§‹åŒ–ç”± OpenLLM ç®¡ç†çš„ LLMã€‚é€™å°æ–¼é–‹ç™¼ç›®çš„å¾ˆæœ‰ç”¨ï¼Œä¸¦å…è¨±é–‹ç™¼äººå“¡å¿«é€Ÿå˜—è©¦ä¸åŒé¡å‹çš„ LLMã€‚

å°‡ LLM æ‡‰ç”¨ç¨‹åºè½‰ç§»åˆ°ç”Ÿç”¢ç’°å¢ƒæ™‚ï¼Œæˆ‘å€‘å»ºè­°å–®ç¨éƒ¨ç½² OpenLLM æœå‹™å™¨ä¸¦é€šéä¸Šé¢æ¼”ç¤ºçš„ `server_url` é¸é …é€²è¡Œè¨ªå•ã€‚

è¦é€šé LangChain åŒ…è£å™¨åœ¨æœ¬åœ°åŠ è¼‰ LLMï¼š

```python
from langchain.llms import OpenLLM

llm = OpenLLM(
    model_name="dolly-v2",
    model_id="databricks/dolly-v2-3b",
    temperature=0.94,
    repetition_penalty=1.2,
)
```

API Reference:

- [OpenLLM](https://api.python.langchain.com/en/latest/llms/langchain.llms.openllm.OpenLLM.html)

### èˆ‡ LLMChain æ•´åˆ

```python
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# æ§‹å»º prompt ç¯„æœ¬
template = "What is a good name for a company that makes {product}?"

prompt = PromptTemplate(template=template, input_variables=["product"])

# æ§‹å»º llm_chain çš„å¯¦ä¾‹
llm_chain = LLMChain(prompt=prompt, llm=llm)

# å‚³å…¥ prompt ç¯„æœ¬åƒæ•¸èˆ‡è§¸å‹• LLM ä¾†ç”Ÿæˆçµæœ
generated = llm_chain.run(product="mechanical keyboard")

print(generated)
```

API Reference:

- [PromptTemplate]()
- [LLMChain]()