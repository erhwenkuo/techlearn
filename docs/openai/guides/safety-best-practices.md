# 安全最佳實踐

## 使用免費的審核 API

OpenAI 的[審核 API](https://platform.openai.com/docs/guides/moderation) 是免費使用的，可以幫助減少完成中不安全內容的頻率。或者，您可能希望開發適合您的用例的自己的內容過濾系統。

## 對抗性測試

我們建議對您的應用程式進行 "red-teaming" 測試，以確保其能夠抵禦對抗性輸入。透過廣泛的輸入和用戶行為測試您的產品，包括代表性的集合和反映有人試圖「破壞」您的應用程式的行為。它是否偏離了主題？有人可以透過 **提示注入** 輕鬆重定向該功能嗎？比如 “ignore the previous instructions and do this instead”?

## 人在迴路中 (HITL)

在任何可能的情況下，我們建議在實際應用之前由人類審查輸出結果。在高風險領域和代碼生成中，這尤其關鍵。人類應該意識到系統的局限性，並且能夠獲取驗證輸出所需的任何信息（例如，如果應用程式總結筆記，人類應該能夠輕鬆訪問原始筆記以便參考）。

## 提示工程

“提示工程” 可以幫助限制輸出文本的主題和語氣。這降低了生成不希望的內容的機會，即使用戶試圖生成它。為模型提供額外的上下文（例如，在新輸入之前提供一些期望行為的高質量例子）可以更容易地引導模型的輸出朝著期望的方向發展。

## 了解你的用戶

一般來說，使用者應該需要註冊並登錄才能訪問您的服務。將此服務與現有帳戶（例如 Gmail、LinkedIn 或 Facebook 登錄）相關聯可能有助於，但對於所有用例可能並不適用。要求提供信用卡或身份證明文件可以進一步降低風險。

## 限制使用者輸入並限制輸出令牌

限制使用者輸入到提示的文字數量有助於避免提示注入。限制輸出令牌的數量有助於減少濫用的可能性。

縮小輸入或輸出範圍，尤其是來自可信來源，有助於減少應用程序中可能發生的濫用程度。

透過經過驗證的下拉選單字段（例如，維基百科上的電影列表）允許使用者輸入，可能比允許開放式文本輸入更安全。

在可能的情況下，從後端返回經過驗證的材料集的輸出，可能比返回新生成的內容更安全（例如，將客戶查詢引導到最匹配的現有客戶支援文章，而不是試圖從頭回答詢問）。

## 允許用戶報告問題

使用者通常應該有一個方便的方法來報告關於應用行為的不當功能或其他問題（列出的電子郵件地址、提交工單的方法等）。這種方法應由人類監控並根據情況進行回應。

## 了解並溝通限制

從產生不正確的資訊、冒犯性的輸出、偏見等問題，語言模型可能需要進行重大修改才能適應每種用例。請考慮模型是否適合您的目的，評估 API 在各種可能的輸入上的表現，以確定可能降低 API 表現的情況。請考慮您的客戶基礎及他們將使用的輸入範圍，並確保他們的期望得到適當的校準。

## 最終用戶 ID


在您的請求中傳送最終使用者的ID可以是一個有用的工具，它可以幫助 OpenAI 監控和檢測濫用。這使 OpenAI 在檢測到應用中的任何政策違規時，能夠向您的團隊提供更具操作性的反饋。

這些 ID 應該是一個能夠唯一識別每個使用者的字符串。我們建議使用其用戶名或電子郵件地址的哈希值，以避免向我們發送任何識別信息。如果您向非登錄用戶提供產品預覽，您可以改為傳送會話 ID。

您可以通過以下方式在 API 請求中使用最終使用者 ID，將其包含在 user 參數中：

```bash
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
  "model": "gpt-3.5-turbo-instruct",
  "prompt": "This is a test",
  "max_tokens": 5,
  "user": "user123456"
}'
```

